{"cells":[{"cell_type":"markdown","metadata":{"id":"fZT1CoCvrWmm"},"source":["#**Neural Networks Project**<br>\n","**Implementing the paper [Pay Attention to MLPs](https://arxiv.org/pdf/2105.08050v1.pdf)**<br>\n","\n","by *Daniel Caliman* (2122749, calimandaniel5@gmail.com) and *Nikolas Jochens* (2118698, nj@andaco.de)"]},{"cell_type":"markdown","metadata":{},"source":["*For the current project, we will user the CIFAR-10 Dataset. The dataset is a collection of images that are commonly used to train machine learning and computer vision algorithms. It is one of the most widely used datasets for machine learning research. The CIFAR-10 dataset contains 60,000 32x32 color images in 10 different classes. The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. There are 6,000 images of each class.*"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","import torch\n","import torch.nn as nn\n","from typing import Optional\n","import einops\n","from tqdm import tqdm\n","import numpy as np\n","from PIL import Image"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["# hyperparameters for vision and language models\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","batch_size = 64\n","\n","n_epochs = 30\n","img_size = 32\n","n_classes = 10\n","lr = 0.001\n","\n","tensor_transforms = transforms.Compose([transforms.ToTensor()])\n","print(device) # check if GPU is available"]},{"cell_type":"code","execution_count":50,"metadata":{"executionInfo":{"elapsed":11579,"status":"ok","timestamp":1704794490932,"user":{"displayName":"Nikolas Jochens","userId":"14426300070837999578"},"user_tz":-60},"id":"FVSok8y1k5ss"},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","50000 torch.Size([64, 3, 32, 32]) torch.Size([64])\n"]}],"source":["train_data = datasets.CIFAR10(\"data/\", train=True, download=True, transform=tensor_transforms)\n","validation_data = datasets.CIFAR10(\"data/\", train=False, download=True, transform=tensor_transforms)\n","train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","validation_loader = DataLoader(validation_data, batch_size=batch_size, shuffle=False)\n","x, y = next(iter(train_loader))\n","print(len(train_data), x.shape, y.shape)"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[],"source":["class SpacialGatingUnit(nn.Module):\n","\n","    def __init__(self, d_z: int, seq_len: int):\n","        super().__init__()\n","        self.norm = nn.LayerNorm([d_z // 2])\n","        self.weight = nn.Parameter(torch.zeros(seq_len, seq_len).uniform_(-0.01, 0.01), requires_grad=True)\n","        self.bias = nn.Parameter(torch.ones(seq_len), requires_grad=True)\n","\n","    def forward(self, z: torch.Tensor, mask: Optional[torch.Tensor] = None):\n","        seq_len = z.shape[0]\n","        z1, z2 = torch.chunk(z, 2, dim=-1)\n","        if mask is not None:\n","            assert mask.shape[0] == 1 or mask.shape[0] == seq_len\n","            assert mask.shape[1] == seq_len\n","            assert mask.shape[2] == 1\n","            mask = mask[:, :, 0]\n","\n","        z2 = self.norm(z2)\n","        weight = self.weight[:seq_len, :seq_len]\n","        if mask is not None:\n","            weight = weight * mask\n","        z2 = torch.einsum('ij,jbd->ibd', weight, z2) + self.bias[:seq_len, None, None]\n","        return z1 * z2"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["class GMLPBlock(nn.Module):\n","    def __init__(self, d_model: int, d_ffn: int, seq_len: int):\n","        super().__init__()\n","        self.norm = nn.LayerNorm([d_model])\n","        self.activation = nn.GELU()\n","        self.proj1 = nn.Linear(d_model, d_ffn)\n","        self.sgu = SpacialGatingUnit(d_ffn, seq_len)\n","        self.proj2 = nn.Linear(d_ffn // 2, d_model)\n","        self.size = d_model\n","\n","    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None):\n","        shortcut = x\n","        x = self.norm(x)\n","        z = self.activation(self.proj1(x))\n","        z = self.sgu(z, mask)\n","        z = self.proj2(z)\n","\n","        return z + shortcut\n"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":["class gMLP(nn.Module):\n","    def __init__(self, seq_len=256, d_model=256, d_ffn=512, n_layers=6):\n","        super().__init__()\n","        self.blocks = nn.Sequential(\n","            *[GMLPBlock(d_model, d_ffn, seq_len) for _ in range(n_layers)]\n","        )\n","\n","    def forward(self, x):\n","        return self.blocks(x)"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["class gMLPVisionModel(nn.Module):\n","    def __init__(self, in_channels=3, image_size=256, patch_size=4, d_model=32, d_ffn=64, n_layers=6, n_classes=1000):\n","        super().__init__()\n","        assert image_size % patch_size == 0, \"image size must be divisible by patch size!!\"\n","        n_patches = (image_size // patch_size) ** 2\n","        self.patch_embedding = nn.Conv2d(in_channels, d_model, kernel_size=patch_size, stride=patch_size)\n","        self.gmlp = gMLP(n_patches, d_model, d_ffn, n_layers)\n","        self.fc_out = nn.Linear(d_model, n_classes)\n","\n","    def forward(self, x):\n","        x = self.patch_embedding(x)\n","        x = einops.rearrange(x, \"b c h w -> b (h w) c\")\n","        x = self.gmlp(x)\n","        x = x.mean(1)\n","        out = self.fc_out(x)\n","        return out"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 10])\n"]}],"source":["gmlp_vm = gMLPVisionModel(n_classes=n_classes, image_size = 32).to(device)\n","inp = torch.randn(1, 3, img_size, img_size).to(device)\n","out = gmlp_vm(inp)\n","print(out.shape)\n","del inp, out"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[],"source":["optimizer_vm = torch.optim.Adam(gmlp_vm.parameters(), lr=lr)\n","loss_fn_vm = nn.CrossEntropyLoss()\n","def get_accuracy(preds, y):\n","    preds = preds.argmax(dim=1, keepdim=True)\n","    correct = preds.squeeze(1).eq(y)\n","    acc = correct.sum() / torch.FloatTensor([y.shape[0]]).to(device)\n","    return acc"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["def loop_vm(net, loader, is_train):\n","    net.train(is_train)\n","    losses = []\n","    accs = []\n","    pbar = tqdm(loader, total=len(loader))\n","    for x, y in pbar:\n","        x = x.to(device)\n","        y = y.to(device)\n","        with torch.set_grad_enabled(is_train):\n","            preds = net(x)\n","            loss = loss_fn_vm(preds, y)\n","            acc = get_accuracy(preds, y)\n","            losses.append(loss.item())\n","            accs.append(acc.item())\n","        if is_train:\n","            optimizer_vm.zero_grad()\n","            loss.backward()\n","            optimizer_vm.step()\n","        pbar.set_description(f'epoch={epoch}, train={int(is_train)}, loss={np.mean(losses):.4f}, acc={np.mean(accs):.4f}')"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["epoch=0, train=1, loss=1.9171, acc=0.2753: 100%|██████████| 782/782 [00:36<00:00, 21.35it/s]\n","epoch=0, train=0, loss=1.7428, acc=0.3398: 100%|██████████| 157/157 [00:05<00:00, 31.04it/s]\n","epoch=1, train=1, loss=1.6547, acc=0.3826: 100%|██████████| 782/782 [00:32<00:00, 24.41it/s]\n","epoch=1, train=0, loss=1.5855, acc=0.4174: 100%|██████████| 157/157 [00:04<00:00, 36.90it/s]\n","epoch=2, train=1, loss=1.5374, acc=0.4368: 100%|██████████| 782/782 [00:26<00:00, 29.45it/s]\n","epoch=2, train=0, loss=1.5457, acc=0.4324: 100%|██████████| 157/157 [00:03<00:00, 51.53it/s]\n","epoch=3, train=1, loss=1.4659, acc=0.4650: 100%|██████████| 782/782 [00:27<00:00, 28.77it/s]\n","epoch=3, train=0, loss=1.4561, acc=0.4593: 100%|██████████| 157/157 [00:04<00:00, 35.93it/s]\n","epoch=4, train=1, loss=1.4255, acc=0.4831: 100%|██████████| 782/782 [00:27<00:00, 28.34it/s]\n","epoch=4, train=0, loss=1.3946, acc=0.4874: 100%|██████████| 157/157 [00:02<00:00, 64.57it/s]\n","epoch=5, train=1, loss=1.3838, acc=0.4961: 100%|██████████| 782/782 [00:25<00:00, 30.43it/s]\n","epoch=5, train=0, loss=1.4388, acc=0.4764: 100%|██████████| 157/157 [00:02<00:00, 53.44it/s]\n","epoch=6, train=1, loss=1.3510, acc=0.5106: 100%|██████████| 782/782 [00:26<00:00, 30.03it/s]\n","epoch=6, train=0, loss=1.3383, acc=0.5064: 100%|██████████| 157/157 [00:03<00:00, 46.29it/s]\n","epoch=7, train=1, loss=1.3186, acc=0.5246: 100%|██████████| 782/782 [00:26<00:00, 29.82it/s]\n","epoch=7, train=0, loss=1.3222, acc=0.5225: 100%|██████████| 157/157 [00:04<00:00, 37.98it/s]\n","epoch=8, train=1, loss=1.2951, acc=0.5319: 100%|██████████| 782/782 [00:25<00:00, 30.98it/s]\n","epoch=8, train=0, loss=1.2753, acc=0.5333: 100%|██████████| 157/157 [00:04<00:00, 38.96it/s]\n","epoch=9, train=1, loss=1.2563, acc=0.5511: 100%|██████████| 782/782 [00:30<00:00, 25.37it/s]\n","epoch=9, train=0, loss=1.2387, acc=0.5475: 100%|██████████| 157/157 [00:03<00:00, 44.18it/s]\n","epoch=10, train=1, loss=1.2338, acc=0.5558: 100%|██████████| 782/782 [00:29<00:00, 26.08it/s]\n","epoch=10, train=0, loss=1.2229, acc=0.5526: 100%|██████████| 157/157 [00:03<00:00, 43.95it/s]\n","epoch=11, train=1, loss=1.2132, acc=0.5653: 100%|██████████| 782/782 [00:41<00:00, 18.69it/s]\n","epoch=11, train=0, loss=1.2147, acc=0.5610: 100%|██████████| 157/157 [00:04<00:00, 35.03it/s]\n","epoch=12, train=1, loss=1.1904, acc=0.5758: 100%|██████████| 782/782 [00:40<00:00, 19.36it/s]\n","epoch=12, train=0, loss=1.2223, acc=0.5604: 100%|██████████| 157/157 [00:04<00:00, 31.63it/s]\n","epoch=13, train=1, loss=1.1743, acc=0.5809: 100%|██████████| 782/782 [00:37<00:00, 20.94it/s]\n","epoch=13, train=0, loss=1.1873, acc=0.5720: 100%|██████████| 157/157 [00:03<00:00, 43.66it/s]\n","epoch=14, train=1, loss=1.1595, acc=0.5863: 100%|██████████| 782/782 [00:28<00:00, 27.52it/s]\n","epoch=14, train=0, loss=1.1801, acc=0.5736: 100%|██████████| 157/157 [00:04<00:00, 34.02it/s]\n","epoch=15, train=1, loss=1.1511, acc=0.5868:  83%|████████▎ | 646/782 [00:24<00:05, 26.04it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[58], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[1;32m----> 2\u001b[0m     loop_vm(gmlp_vm, train_loader, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m     loop_vm(gmlp_vm, validation_loader, \u001b[38;5;28;01mFalse\u001b[39;00m)\n","Cell \u001b[1;32mIn[57], line 6\u001b[0m, in \u001b[0;36mloop_vm\u001b[1;34m(net, loader, is_train)\u001b[0m\n\u001b[0;32m      4\u001b[0m accs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(loader, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(loader))\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[0;32m      7\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      8\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n","File \u001b[1;32mc:\\Users\\calim\\anaconda3\\envs\\rl\\Lib\\site-packages\\tqdm\\std.py:1192\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1190\u001b[0m dt \u001b[38;5;241m=\u001b[39m cur_t \u001b[38;5;241m-\u001b[39m last_print_t\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dt \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m mininterval \u001b[38;5;129;01mand\u001b[39;00m cur_t \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m min_start_t:\n\u001b[1;32m-> 1192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(n \u001b[38;5;241m-\u001b[39m last_print_n)\n\u001b[0;32m   1193\u001b[0m     last_print_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_print_n\n\u001b[0;32m   1194\u001b[0m     last_print_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_print_t\n","File \u001b[1;32mc:\\Users\\calim\\anaconda3\\envs\\rl\\Lib\\site-packages\\tqdm\\std.py:1243\u001b[0m, in \u001b[0;36mtqdm.update\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ema_dn(dn)\n\u001b[0;32m   1242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ema_dt(dt)\n\u001b[1;32m-> 1243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefresh(lock_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlock_args)\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic_miniters:\n\u001b[0;32m   1245\u001b[0m     \u001b[38;5;66;03m# If no `miniters` was specified, adjust automatically to the\u001b[39;00m\n\u001b[0;32m   1246\u001b[0m     \u001b[38;5;66;03m# maximum iteration rate seen so far between two prints.\u001b[39;00m\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;66;03m# e.g.: After running `tqdm.update(5)`, subsequent\u001b[39;00m\n\u001b[0;32m   1248\u001b[0m     \u001b[38;5;66;03m# calls to `tqdm.update()` will only cause an update after\u001b[39;00m\n\u001b[0;32m   1249\u001b[0m     \u001b[38;5;66;03m# at least 5 more iterations.\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxinterval \u001b[38;5;129;01mand\u001b[39;00m dt \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxinterval:\n","File \u001b[1;32mc:\\Users\\calim\\anaconda3\\envs\\rl\\Lib\\site-packages\\tqdm\\std.py:1348\u001b[0m, in \u001b[0;36mtqdm.refresh\u001b[1;34m(self, nolock, lock_args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1347\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m-> 1348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplay()\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nolock:\n\u001b[0;32m   1350\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[1;32mc:\\Users\\calim\\anaconda3\\envs\\rl\\Lib\\site-packages\\tqdm\\std.py:1496\u001b[0m, in \u001b[0;36mtqdm.display\u001b[1;34m(self, msg, pos)\u001b[0m\n\u001b[0;32m   1494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pos:\n\u001b[0;32m   1495\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoveto(pos)\n\u001b[1;32m-> 1496\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__str__\u001b[39m() \u001b[38;5;28;01mif\u001b[39;00m msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m msg)\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pos:\n\u001b[0;32m   1498\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoveto(\u001b[38;5;241m-\u001b[39mpos)\n","File \u001b[1;32mc:\\Users\\calim\\anaconda3\\envs\\rl\\Lib\\site-packages\\tqdm\\std.py:462\u001b[0m, in \u001b[0;36mtqdm.status_printer.<locals>.print_status\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_status\u001b[39m(s):\n\u001b[0;32m    461\u001b[0m     len_s \u001b[38;5;241m=\u001b[39m disp_len(s)\n\u001b[1;32m--> 462\u001b[0m     fp_write(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m s \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mmax\u001b[39m(last_len[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m len_s, \u001b[38;5;241m0\u001b[39m)))\n\u001b[0;32m    463\u001b[0m     last_len[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m len_s\n","File \u001b[1;32mc:\\Users\\calim\\anaconda3\\envs\\rl\\Lib\\site-packages\\tqdm\\std.py:456\u001b[0m, in \u001b[0;36mtqdm.status_printer.<locals>.fp_write\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfp_write\u001b[39m(s):\n\u001b[0;32m    455\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28mstr\u001b[39m(s))\n\u001b[1;32m--> 456\u001b[0m     fp_flush()\n","File \u001b[1;32mc:\\Users\\calim\\anaconda3\\envs\\rl\\Lib\\site-packages\\tqdm\\utils.py:195\u001b[0m, in \u001b[0;36mDisableOnWriteError.disable_on_exception.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 195\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m5\u001b[39m:\n","File \u001b[1;32mc:\\Users\\calim\\anaconda3\\envs\\rl\\Lib\\site-packages\\ipykernel\\iostream.py:564\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(evt\u001b[38;5;241m.\u001b[39mset)\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;66;03m# and give a timeout to avoid\u001b[39;00m\n\u001b[1;32m--> 564\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt\u001b[38;5;241m.\u001b[39mwait(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush_timeout):\n\u001b[0;32m    565\u001b[0m         \u001b[38;5;66;03m# write directly to __stderr__ instead of warning because\u001b[39;00m\n\u001b[0;32m    566\u001b[0m         \u001b[38;5;66;03m# if this is happening sys.stderr may be the problem.\u001b[39;00m\n\u001b[0;32m    567\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIOStream.flush timed out\u001b[39m\u001b[38;5;124m\"\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39m__stderr__)\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[1;32mc:\\Users\\calim\\anaconda3\\envs\\rl\\Lib\\threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    620\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 622\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n","File \u001b[1;32mc:\\Users\\calim\\anaconda3\\envs\\rl\\Lib\\threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mTrue\u001b[39;00m, timeout)\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for epoch in range(n_epochs):\n","    loop_vm(gmlp_vm, train_loader, True)\n","    loop_vm(gmlp_vm, validation_loader, False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["@torch.no_grad()\n","def recognize_img(net, img):\n","    net.eval()\n","    img = Image.open(img).convert(\"RGB\")\n","    img = tensor_transforms(img).to(device)\n","    pred = net(img.unsqueeze(0))\n","    pred = pred.argmax(dim=1)\n","    return train_data.classes[pred.item()]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["bird\n"]}],"source":["out = recognize_img(gmlp_vm, 'dog.jpg')\n","print(out)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMoSQ5SLdBhOeeIymgnT1/N","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
